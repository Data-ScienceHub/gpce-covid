2022-12-24 06:17:29.733411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-24 06:17:34.240323: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-12-24 06:17:49.130512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/centos-7.4/anaconda3/current/lib:/sw/centos-7.4/cudnn/current/lib64:/sw/centos-7.4/cuda/current/extras/CUPTI/lib64:/sw/centos-7.4/cuda/current/lib64:/u/mi3se/anaconda3/envs/ml/lib/:~/anaconda3/envs/ml/lib
2022-12-24 06:17:49.131531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /sw/centos-7.4/anaconda3/current/lib:/sw/centos-7.4/cudnn/current/lib64:/sw/centos-7.4/cuda/current/extras/CUPTI/lib64:/sw/centos-7.4/cuda/current/lib64:/u/mi3se/anaconda3/envs/ml/lib/:~/anaconda3/envs/ml/lib
2022-12-24 06:17:49.131577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[32m[I 2022-12-24 06:20:58,319][0m A new study created in RDB with name: nhits[0m
[32m[I 2022-12-24 16:01:56,831][0m Trial 2 finished with value: 0.7224880648633539 and parameters: {'learning_rate': 0.0007599818473288894, 'dropout': 0.2, 'layers': 4, 'batch_size': 32}. Best is trial 2 with value: 0.7224880648633539.[0m
[32m[I 2022-12-24 18:32:37,876][0m Trial 0 finished with value: 0.5691587870304261 and parameters: {'learning_rate': 0.00023912549385861044, 'dropout': 0.3, 'layers': 4, 'batch_size': 64}. Best is trial 0 with value: 0.5691587870304261.[0m
[32m[I 2022-12-24 19:22:59,365][0m Trial 1 finished with value: 0.5499149685597409 and parameters: {'learning_rate': 0.00030572402539168393, 'dropout': 0.1, 'layers': 4, 'batch_size': 64}. Best is trial 1 with value: 0.5499149685597409.[0m
[32m[I 2022-12-24 20:39:39,007][0m Trial 9 finished with value: 0.43723959896111864 and parameters: {'learning_rate': 4.263864648144939e-05, 'dropout': 0.1, 'layers': 3, 'batch_size': 32}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-24 21:27:18,367][0m Trial 7 finished with value: 0.49240888464977023 and parameters: {'learning_rate': 0.0001106401913553003, 'dropout': 0.1, 'layers': 4, 'batch_size': 32}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-24 23:18:16,255][0m Trial 11 finished with value: 0.4927946915146009 and parameters: {'learning_rate': 2.488673680649371e-05, 'dropout': 0.0, 'layers': 2, 'batch_size': 32}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 05:50:57,470][0m Trial 13 finished with value: 0.5008963295728664 and parameters: {'learning_rate': 0.00013521005687968304, 'dropout': 0.3, 'layers': 3, 'batch_size': 64}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 05:52:34,926][0m Trial 16 finished with value: 0.5300298277987613 and parameters: {'learning_rate': 0.0008137220996806673, 'dropout': 0.0, 'layers': 3, 'batch_size': 64}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 08:42:04,211][0m Trial 17 finished with value: 0.569377215450854 and parameters: {'learning_rate': 0.000822746844869, 'dropout': 0.0, 'layers': 4, 'batch_size': 64}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 10:32:17,950][0m Trial 4 finished with value: 0.4767291761072491 and parameters: {'learning_rate': 0.00017925490767796106, 'dropout': 0.0, 'layers': 4, 'batch_size': 64}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 14:18:05,987][0m Trial 5 finished with value: 0.45990554798462957 and parameters: {'learning_rate': 0.0003705794020953729, 'dropout': 0.1, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 14:30:19,870][0m Trial 12 finished with value: 0.47849959574000295 and parameters: {'learning_rate': 3.040276439999577e-05, 'dropout': 0.1, 'layers': 2, 'batch_size': 32}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 18:00:55,670][0m Trial 10 finished with value: 0.4763933810194826 and parameters: {'learning_rate': 4.407365091999408e-05, 'dropout': 0.0, 'layers': 3, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 18:15:37,405][0m Trial 3 finished with value: 0.5345168009489298 and parameters: {'learning_rate': 0.00039640324316892866, 'dropout': 0.2, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 18:56:56,200][0m Trial 20 finished with value: 0.47941267808247134 and parameters: {'learning_rate': 1.7126369561758652e-05, 'dropout': 0.2, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 19:26:41,585][0m Trial 19 finished with value: 0.5350689368509504 and parameters: {'learning_rate': 0.00018019256698548512, 'dropout': 0.1, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 19:58:33,853][0m Trial 14 finished with value: 0.46722284759739746 and parameters: {'learning_rate': 1.816839265723783e-05, 'dropout': 0.1, 'layers': 3, 'batch_size': 64}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 20:21:56,205][0m Trial 18 finished with value: 0.6458058784343456 and parameters: {'learning_rate': 0.000569248445775263, 'dropout': 0.2, 'layers': 4, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 20:57:40,427][0m Trial 8 finished with value: 0.46374804453710344 and parameters: {'learning_rate': 2.645966071554459e-05, 'dropout': 0.0, 'layers': 3, 'batch_size': 32}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 21:14:36,347][0m Trial 6 finished with value: 0.5006153612225764 and parameters: {'learning_rate': 0.00030834238940380355, 'dropout': 0.2, 'layers': 2, 'batch_size': 64}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 21:31:37,783][0m Trial 21 finished with value: 0.4895851516732554 and parameters: {'learning_rate': 2.7992932209239884e-05, 'dropout': 0.2, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 22:10:54,990][0m Trial 15 finished with value: 0.5121983542649551 and parameters: {'learning_rate': 1.0366259364889604e-05, 'dropout': 0.3, 'layers': 3, 'batch_size': 64}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 22:37:55,780][0m Trial 23 finished with value: 0.46316405991459203 and parameters: {'learning_rate': 5.3226165138134675e-05, 'dropout': 0.2, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-25 23:16:17,934][0m Trial 22 finished with value: 0.47099836505632414 and parameters: {'learning_rate': 2.4733733386013365e-05, 'dropout': 0.2, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
[32m[I 2022-12-26 00:09:05,661][0m Trial 24 finished with value: 0.46729250480991646 and parameters: {'learning_rate': 6.0220797484396536e-05, 'dropout': 0.2, 'layers': 2, 'batch_size': 128}. Best is trial 9 with value: 0.43723959896111864.[0m
   FIPS  AgeDist  HealthDisp  ... LinearSpace  SinWeekly  CosWeekly
0  1001   0.1611       4.202  ...         0.0    -0.9749    -0.2225
1  1001   0.1611       4.202  ...         0.0    -0.7818     0.6235
2  1001   0.1611       4.202  ...         0.0     0.0000     1.0000

[3 rows x 14 columns]
Shapes: train (2010880, 14), validation (87976, 14), test (87976, 14).
Number of finished trials:  25
Best trial:
  Value:  0.43723959896111864
  Params: 
    batch_size: 32
    dropout: 0.1
    layers: 3
    learning_rate: 4.263864648144939e-05
