{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LopEAYzbELVA"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j724k07rELVB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# disable chained assignments\n",
        "pd.options.mode.chained_assignment = None \n",
        "import os, gc\n",
        "import optuna, optuna_dashboard\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "from models import build_BiLSTM\n",
        "from utils import *\n",
        "from splits import *\n",
        "\n",
        "SEED = 7\n",
        "tf.random.set_seed(SEED)\n",
        "VERBOSE = 0\n",
        "Split = Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_folder = 'scratch/tune_BiLSTM'\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emlXwxlMELVB"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4ZnvkkJELVC",
        "outputId": "b7d0c71d-75d6-4308-ee80-89e029d2f68d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   FIPS  AgeDist  HealthDisp       Date  DiseaseSpread  Transmission  \\\n",
            "0  2261    0.014         8.8 2020-02-29            0.0           0.0   \n",
            "1  2261    0.014         8.8 2020-03-01            0.0           0.0   \n",
            "2  2261    0.014         8.8 2020-03-02            0.0           0.0   \n",
            "\n",
            "   VaccinationFull  SocialDist  Cases  TimeFromStart  SinWeekly  CosWeekly  \n",
            "0              0.0         0.5    0.0              0     -0.975     -0.223  \n",
            "1              0.0         0.5    0.0              1     -0.782      0.623  \n",
            "2              0.0         0.5    0.0              2      0.000      1.000  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../TFT-pytorch/2022_May_cleaned/Top_100.csv')\n",
        "df['Date'] = pd.to_datetime(df['Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class Config:\n",
        "    static_features = ['AgeDist', 'HealthDisp']\n",
        "    past_features = ['DiseaseSpread', 'Transmission', 'VaccinationFull', 'SocialDist']\n",
        "    known_future = ['SinWeekly', 'CosWeekly']\n",
        "    time_index = 'TimeFromStart' # note that this is an index feature commonly used by all timeseries models\n",
        "\n",
        "    features =  [time_index] + static_features + past_features + known_future\n",
        "    targets = ['Cases']\n",
        "    group_id = 'FIPS'\n",
        "    selected_columns = features + targets\n",
        "    input_sequence_length = 13\n",
        "    output_sequence_length = 15\n",
        "    batch_size = 64\n",
        "    buffer_size = 1000\n",
        "    epochs = 200\n",
        "    early_stopping_patience = 5\n",
        "    loss = 'mse'\n",
        "\n",
        "targets = Config.targets\n",
        "group_id = Config.group_id\n",
        "input_sequence_length = Config.output_sequence_length\n",
        "output_sequence_length = Config.output_sequence_length\n",
        "output_size = len(targets) * output_sequence_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gy6DE69ELVD"
      },
      "source": [
        "## Split and scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf0nwz_qELVD",
        "outputId": "23b9687e-e6fc-4867-eb5a-ea8412cf968d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: train (64000, 12), validation (3000, 12), test (3000, 12).\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = split_data(df, Split, input_sequence_length)\n",
        "train_df, val_df, test_df, feature_scaler, target_scaler = scale_data(\n",
        "    train_df, val_df, test_df, Config.features, targets\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_Jq3uSELVE"
      },
      "source": [
        "## Window generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_AYybFIELVE",
        "outputId": "8aa42b3c-460b-4517-ec36-85577287c291"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b38dc73a2c654092b2a374cc8c8a8f84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: data (61300, 13, 10), labels (61300, 15).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ca9dec2a5474ad9988cc6192a487cba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: data (300, 13, 10), labels (300, 15).\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = prepare_dataset(\n",
        "    train_df, Config, disable_progress_bar=(VERBOSE!=1)\n",
        ")\n",
        "x_val, y_val = prepare_dataset(\n",
        "    val_df, Config, disable_progress_bar=(VERBOSE!=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Im3Z1QELVF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOHTAa2eELVF"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 128, step=32)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0, 0.3, step=0.1)\n",
        "    layers = trial.suggest_int(\"layers\", 2, 4, step=1)\n",
        "\n",
        "    model = build_BiLSTM(\n",
        "        x_train.shape[1:], output_size=output_size, loss=Config.loss, \n",
        "        hidden_size=hidden_size, dropout=dropout, \n",
        "        learning_rate=learning_rate, layers=layers\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def create_dataset(trial):\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "    train_data = cache_data(\n",
        "        x_train, y_train, batch_size=batch_size, \n",
        "        buffer_size=Config.buffer_size\n",
        "    )\n",
        "    val_data = cache_data(\n",
        "        x_val, y_val, batch_size=batch_size, \n",
        "    )\n",
        "    return train_data, val_data\n",
        "\n",
        "def objective(trial):\n",
        "    model = create_model(trial)\n",
        "    train_data, val_data = create_dataset(trial)\n",
        "    \n",
        "    early_stopping = EarlyStopping(\n",
        "        patience = Config.early_stopping_patience, \n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        filepath=os.path.join(output_folder, 'model.h5'), \n",
        "        save_best_only=True, save_weights_only=True\n",
        "    )\n",
        "    model.fit(\n",
        "        train_data, validation_data=val_data,\n",
        "        epochs=2,  \n",
        "        callbacks=[early_stopping, model_checkpoint],\n",
        "        verbose=VERBOSE\n",
        "    )\n",
        "    model.load_weights(model_checkpoint.filepath)\n",
        "    val_loss = model.evaluate(val_data, verbose=VERBOSE)\n",
        "\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-12-23 00:06:43,468]\u001b[0m Using an existing study with name 'BiLSTM' instead of creating a new one.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "study_name = 'BiLSTM'\n",
        "storage_name = f\"sqlite:///{study_name}.db\"\n",
        "\n",
        "study = optuna.create_study(\n",
        "    study_name=study_name, storage=storage_name, direction='minimize', load_if_exists=True\n",
        ")\n",
        "study.optimize(\n",
        "    objective, n_trials=25, n_jobs=-1, \n",
        "    gc_after_trial=True, show_progress_bar=(VERBOSE==1)\n",
        ")\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Parameters: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig =optuna.visualization.plot_param_importances(study)\n",
        "optuna.visualization.plot_optimization_history(study)\n",
        "df = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
        "df.round(6).to_csv(os.path.join(output_folder, 'trials.csv'), index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "43fc5fbfa959c1c54ddf7d7acab30a2019a504b895513ba1ba722e7f395657c0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
